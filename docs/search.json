[
  {
    "objectID": "spikesorter_tutorial.html",
    "href": "spikesorter_tutorial.html",
    "title": "Spike Sorting Tutorial",
    "section": "",
    "text": "Before sorting, there are several key details to understand:\n\n\nMulti-channel data from the Intan Recording Software (RHX) is saved as binary data, meaning that there is no information in the data file to tell your computer details about the information inside. Compare this to a .MAT file, which includes some information about how many variables there are, how big the variables are etc. For binary data, we need to know some details of how it was obtained to understand how to open it.\n\n\nBinary data is is a data format where the user needs to specify how the data is stored in computer memory. This includes the datatype (e.g. Int16), and how the data is arranged (e.g. channels x time) array.\nIntan data files are called amplifier.dat. Each voltage value from the recording software is recorded as a Int16 value, meaning that the computer dedicates 16-bits (1s and 0s) to storing the values, and they can be positive or negative. To convert to more meaningful voltage values, Intan tells us that each increment (e.g. from 0 to 1) corresponds to 0.195 uV.\nThe amplifier.dat file is an array of voltage values. We must also know the organization of this array; if the first value is the voltage on the first channel, does the second value correspond to the voltage at the same time from the 2nd channel? Or does it correspond to the voltage at timepoint 2 on channel 1? In other words, is the data organized as channels by time, or time by channels? Electrophysiology data is almost always written as channel_1_time_1, channel_2_time1, channel_3_time_1 etc, or channels by time.\n\n\nBinary data can be converted to voltage vs time by scaling the time axis with the sampling rate and the magnitude axis with the voltage/bit\nWe also must know the sampling rate. For Intan data this is typically 30000 Hz. In other words, each sample is 1/30000 in duration.\n\n\n\nSorting and visualization are greatly aided by knowing the physical relationship between recording channels. Unfortunately, both the connection of the probe to the probe holder and the connection of the probe holder to the headstage scrambles the channel numbers. Additionally, for each probe type/adapter/headstage combination, this relationship will be different.\n\n\nThe channel identifier in saved data (1,2,3 etc) does NOT correspond to the channel ID on the silicon probe\nCommon probe configurations used in the lab, along with useful files can be found at the address below:\nhttps://github.com/paulmthompson/silicon-probes\nFor spike sorting, we will need the electrode.cfg file for the probe type of interest.\n\n\n\nWhat does a well isolated single unit look like? This is a difficult question, and evidence suggests that spike sorting routines are particularly poor at determining this. In fact, when popular programs have been applied to the same data only 10% of spikes have been found by all of the programs (yikes) (Buccino et al. 2020)\nObjective metrics calculated from our data should theoretically aid us in determining if a unit is well isolated, but these metrics can also be misleading if not used carefully. I have seen evidence in the literature that the way metrics are calculated has changed over time, and they have changed in such a way that they are more lenient, perhaps by as much as an order of magnitude.\nIn a well-designed recording rig, even in difficult to record brain areas, we should be able to use strict criteria during manual sorting as well as strict metrics and still have multiple well isolated single units for each recording session.\n\n\n\n\n\n\nTip\n\n\n\nUse sorting metrics to help cleanup the borderline cases. If they are doing the majority of the work you have perhaps mis-identified useful metrics or you are being overly optimistic during your manual sorting about what a unit is and is not.\n\n\n\n\nThe single most important metric is the signal-to-noise ratio. You should have a general idea of this one from experimental time because it should roughly tell you how big is my neuronal signal compared to the noise. I have found at least 3 different ways to calculate this in the literature:\n\\[\\frac{V_{template,peak-to-peak}}{V_{std}} \\tag{1}\\]\n\\[\\frac{V_{template,peak-to-peak}}{V_{peak-to-peak}} \\tag{2}\\]\n\\[\\frac{V_{template,amplitude}}{V_{std}} \\tag{3}\\]\nThe most “correct” SNR by definition is peak-to-peak voltage over root-mean-square voltage (Equation 1), which is roughly equivalent to standard deviation. However, this is a difficult quantity to mentally compute from looking at the raw data, AND this results in the largest SNR values of the three equations. Peak-to-Peak waveform voltage over the noise peak-to-peak voltage (Equation 2) is easy to intuit because it is roughly the height of the spike vs the height of the noise. Note however that this quantity tends to be perhaps 5-10 times smaller than SNR calculated as in Equation 1. This is because the peak-to-peak voltage of the noise is roughly 8 times larger than the standard deviation (The Axon guide, electrophysiology and biophysics laboratory techniques 2012). Consequently, one should recognize that a sensible cutoff of SNR for differentiating signal from noise would also vary by almost an order of magnitude depending on how SNR was calculated.\n\n\nPeak-to-peak voltages are easier to estimate by eye than standard deviations\nI recommend using only peak-to-peak voltages, and using a cutoff of approximately 2. Our spike sorting software and the authors who created it have used a cutoff around this value (1.8 - 2.5) (Nicholas V. Swindale et al. 2023; Nicholas V. Swindale et al. 2017).\nNote that recent cutting edge electrophysiology papers from the International Brain Laboratory have used a similar cutoff of 2.5 with popular algorithms like Kilosort2 (Inagaki et al. 2022). Superficially, this may appear to be more strict than what I am endorsing. However, note that the equation used by these authors is Equation 1, and with this method, SNR=2.5 is barely distinguishable from noise (Figure 1). Confusingly, about 8 years prior, this group used a SNR cutoff of at least 5 (Guo et al. 2014, fig. S3), with average SNR around 10, which is much more reasonable. These gradual decays in quality over time are an important cautionary tale for understanding the underlying methodology.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport copy\n\ndef get_noise_ptp(noise,samples,repetitions):\n  \n  max_noise = np.zeros(repetitions)\n  min_noise = np.zeros(repetitions)\n  noise_ptp = np.zeros(repetitions)\n  \n  for i in range(0,repetitions):\n    subsamples = np.random.choice(noise_std,samples)\n  \n    max_noise[i] = np.max(noise_std)\n    min_noise[i] = np.min(noise_std)\n    noise_ptp[i] = max_noise[i] - min_noise[i]\n    \n  noise_ptp = np.mean(noise_ptp)\n  max_noise = np.mean(max_noise)\n  min_noise = np.mean(min_noise)\n  \n  return noise_ptp,max_noise,min_noise\n  \n  \n\ntemplate = np.array([-0.1513909 , -0.16631116, -0.17847979, -0.18862691, -0.19872002,\n       -0.20880426, -0.21737931, -0.22361187, -0.22874592, -0.23452372,\n       -0.24082686, -0.24489726, -0.24255492, -0.22836725, -0.19307666,\n       -0.1191242 ,  0.02425   ,  0.28417833,  0.71488001,  1.34970811,\n        2.15717331,  3.00861469,  3.70470693,  4.06647289,  4.02591484,\n        3.64727615,  3.07093063,  2.43142789,  1.8080954 ,  1.2247536 ,\n        0.67450634,  0.14624459, -0.36222091, -0.84091953, -1.2741004 ,\n       -1.6452294 , -1.94012256, -2.14839704, -2.26756383, -2.30440089,\n       -2.27405578, -2.19505695, -2.0840863 , -1.95470787, -1.81895549,\n       -1.68644032, -1.56235016, -1.44811373, -1.3434583 , -1.24678163,\n       -1.15489337, -1.06493637, -0.97600263, -0.88764435, -0.79968051,\n       -0.71323625, -0.62895673, -0.54701365, -0.46780424, -0.39222975,\n       -0.32111773, -0.25396762, -0.19020192, -0.13038235, -0.07453424,\n       -0.02132602,  0.02993237,  0.07660115,  0.11522204,  0.14610511,\n        0.17122906,  0.19176712,  0.20754389])\n\nsnr_values = [2.5, 7.5, 15.0]\nnoise_length = 1000\npad = int((noise_length - len(template)) / 2)\n\nmax_template = np.max(template)\nmin_template = np.min(template)\n\ntemplate_ptp = max_template - min_template\n\n(fig,ax) = plt.subplots(1,len(snr_values))\n\nfor i in range(0,len(snr_values)):\n  \n  snr_value = snr_values[i]\n  padded_template = np.zeros(noise_length)\n\n  noise_std = np.random.normal(loc=0.0,scale=template_ptp / snr_value, size=noise_length)\n\n  noise_ptp,max_noise,min_noise = get_noise_ptp(noise_std,len(template),1000)\n\n  template_over_noise = copy.deepcopy(noise_std)\n  template_over_noise[pad:len(template)+pad] += template\n\n  padded_template[pad:len(template) + pad] += template\n\n  ax[i].plot(template_over_noise,color=\"black\",label=\"_Hidden\",linewidth=1.0)\n  ax[i].plot([0,noise_length],[max_template,max_template],linestyle=\"dashed\",color=\"red\",label=\"_Hidden\")\n  ax[i].plot([0,noise_length],[min_template,min_template],linestyle=\"dashed\",color=\"red\",label=\"Template \\n Envelope\")\n  \n  ax[i].plot([0,noise_length],[max_noise,max_noise],linestyle=\"dashed\",color=\"blue\",label=\"_Hidden\")\n  ax[i].plot([0,noise_length],[min_noise,min_noise],linestyle=\"dashed\",color=\"blue\",label=\"Noise \\n Envelope\")\n  #ax[i].plot(padded_template,color=\"red\",alpha=0.2)\n\n  snr_std = np.around(template_ptp / np.std(noise_std),decimals=1)\n  snr_ptp = np.around(template_ptp / (np.max(noise_std) - np.min(noise_std)),decimals=1)\n\n  ax[i].set_title(f\"SNR_std: {snr_std} \\n SNR_ptp: {snr_ptp}\" )\n  ax[i].set_ylim([-9, 9])\n  ax[i].set_xticks([])\n  ax[i].set_yticks([])\n  ax[i].set_xlabel(\"Time\")\n  \n  if i == 0:\n    ax[i].set_ylabel(\"Voltage\")\n  if i == len(ax) - 1:\n    ax[i].legend()\n\n\n\n\n\nFigure 1: SNR calculation comparisons\n\n\n\n\n\n\n\nThe waveform amplitude is part of the SNR calculation, so it is mostly just a kind of sanity check. Some spike sorting programs report this as the absolute value of the largest peak (positive or negative), while others report it as peak-to-peak voltage, which can be as much as double the size for a bi-phasic waveform. I recommend using a cutoff of 100 uV peak-to-peak, although few single units will have an SNR &gt; 2 with an amplitude smaller than 100uV at physiological noise levels.\n\n\n\nIt is common to report metrics relating to the refractory period. Briefly, neurons are inactivated after firing action potentials for a few milliseconds, so it is reasonably to assume that if a sorting algorithm is detecting more waveforms within this “refractory” window, it is either due to noise or multi-unit contamination.\n\n\nMultiunit is used to refer to signals that appear to be from neural activity, but are not sufficiently well isolated to distinguish from one another\nThis is good in theory, but these metrics can be heavily biased downward as a result of temporal lockout built into sorting algorithms. After most sorting algorithms detect threshold crossings, they generally select the waveform, and then impose some lockout period before they look for more threshold crossings. For this reason, they tend to not even look for spikes during this “lockout period.” So a low ISI violation rate can still occur with low SNR units because of the sorting process itself.\nISI violation is reported in multiple ways. The simplest is to calculate the percentage of total spikes that within 1 refractory period width of one another. These tend to be quite low (1-2%).\nThere are more sophisticated methods that try to estimate proportion of spikes that are contaminated by multiunit spiking. There are lots of assumptions in these (such as uncorrelated units) and a stable mean firing rate, which can make these metrics biased upwards for bursty units like we see in the brainstem. They can be useful however. Often these are reported as between 0-1, roughly corresponding to 0% of spiking is contaminated and 100% contaminated.\n\n\n\nAnalysis of neural data usually requires the unit to be present throughout the course of the entire experiment; otherwise changes in activity may be falsely attributed to changes in behavior over that time. There can be abrupt changes in if a unit is present or not (for instance, bumping the experimental rig), but low SNR units could also come and go as they sink above and below the threshold for detection. Good manual sorting should exclude this second time of unit. Similarly, electrode drift may cause the shape of the neuronal waveform to change over time, and the sorting algorithm may falsely assign part of the activity to one unit, and part to another. Again, manual sorting should be able to catch these errors if the unit is sufficiently high SNR.\nA presence ratio is usually the quantity calculated for this purpose, and 0.95 is a reasonable threshold.\n\n\n\nPre-specify some metrics for spike sorting that will serve as a threshold for including neurons in your analysis. However, most neurons that you call single units after manual curation should meet these thresholds anyway. A reasonable criteria matrix is as follows:\n\nRecommended Quality Metrics\n\n\nSNR (peak-to-peak signal / peak-to-peak noise) &gt; 2\n\n\nAmplitude (peak-to-peak) &gt; 100 uV\n\n\nISI violation &lt; 1%\n\n\nMUA contamination &lt; 0.5\n\n\nPresence ratio &gt; 0.95"
  },
  {
    "objectID": "spikesorter_tutorial.html#background",
    "href": "spikesorter_tutorial.html#background",
    "title": "Spike Sorting Tutorial",
    "section": "",
    "text": "Before sorting, there are several key details to understand:\n\n\nMulti-channel data from the Intan Recording Software (RHX) is saved as binary data, meaning that there is no information in the data file to tell your computer details about the information inside. Compare this to a .MAT file, which includes some information about how many variables there are, how big the variables are etc. For binary data, we need to know some details of how it was obtained to understand how to open it.\n\n\nBinary data is is a data format where the user needs to specify how the data is stored in computer memory. This includes the datatype (e.g. Int16), and how the data is arranged (e.g. channels x time) array.\nIntan data files are called amplifier.dat. Each voltage value from the recording software is recorded as a Int16 value, meaning that the computer dedicates 16-bits (1s and 0s) to storing the values, and they can be positive or negative. To convert to more meaningful voltage values, Intan tells us that each increment (e.g. from 0 to 1) corresponds to 0.195 uV.\nThe amplifier.dat file is an array of voltage values. We must also know the organization of this array; if the first value is the voltage on the first channel, does the second value correspond to the voltage at the same time from the 2nd channel? Or does it correspond to the voltage at timepoint 2 on channel 1? In other words, is the data organized as channels by time, or time by channels? Electrophysiology data is almost always written as channel_1_time_1, channel_2_time1, channel_3_time_1 etc, or channels by time.\n\n\nBinary data can be converted to voltage vs time by scaling the time axis with the sampling rate and the magnitude axis with the voltage/bit\nWe also must know the sampling rate. For Intan data this is typically 30000 Hz. In other words, each sample is 1/30000 in duration.\n\n\n\nSorting and visualization are greatly aided by knowing the physical relationship between recording channels. Unfortunately, both the connection of the probe to the probe holder and the connection of the probe holder to the headstage scrambles the channel numbers. Additionally, for each probe type/adapter/headstage combination, this relationship will be different.\n\n\nThe channel identifier in saved data (1,2,3 etc) does NOT correspond to the channel ID on the silicon probe\nCommon probe configurations used in the lab, along with useful files can be found at the address below:\nhttps://github.com/paulmthompson/silicon-probes\nFor spike sorting, we will need the electrode.cfg file for the probe type of interest.\n\n\n\nWhat does a well isolated single unit look like? This is a difficult question, and evidence suggests that spike sorting routines are particularly poor at determining this. In fact, when popular programs have been applied to the same data only 10% of spikes have been found by all of the programs (yikes) (Buccino et al. 2020)\nObjective metrics calculated from our data should theoretically aid us in determining if a unit is well isolated, but these metrics can also be misleading if not used carefully. I have seen evidence in the literature that the way metrics are calculated has changed over time, and they have changed in such a way that they are more lenient, perhaps by as much as an order of magnitude.\nIn a well-designed recording rig, even in difficult to record brain areas, we should be able to use strict criteria during manual sorting as well as strict metrics and still have multiple well isolated single units for each recording session.\n\n\n\n\n\n\nTip\n\n\n\nUse sorting metrics to help cleanup the borderline cases. If they are doing the majority of the work you have perhaps mis-identified useful metrics or you are being overly optimistic during your manual sorting about what a unit is and is not.\n\n\n\n\nThe single most important metric is the signal-to-noise ratio. You should have a general idea of this one from experimental time because it should roughly tell you how big is my neuronal signal compared to the noise. I have found at least 3 different ways to calculate this in the literature:\n\\[\\frac{V_{template,peak-to-peak}}{V_{std}} \\tag{1}\\]\n\\[\\frac{V_{template,peak-to-peak}}{V_{peak-to-peak}} \\tag{2}\\]\n\\[\\frac{V_{template,amplitude}}{V_{std}} \\tag{3}\\]\nThe most “correct” SNR by definition is peak-to-peak voltage over root-mean-square voltage (Equation 1), which is roughly equivalent to standard deviation. However, this is a difficult quantity to mentally compute from looking at the raw data, AND this results in the largest SNR values of the three equations. Peak-to-Peak waveform voltage over the noise peak-to-peak voltage (Equation 2) is easy to intuit because it is roughly the height of the spike vs the height of the noise. Note however that this quantity tends to be perhaps 5-10 times smaller than SNR calculated as in Equation 1. This is because the peak-to-peak voltage of the noise is roughly 8 times larger than the standard deviation (The Axon guide, electrophysiology and biophysics laboratory techniques 2012). Consequently, one should recognize that a sensible cutoff of SNR for differentiating signal from noise would also vary by almost an order of magnitude depending on how SNR was calculated.\n\n\nPeak-to-peak voltages are easier to estimate by eye than standard deviations\nI recommend using only peak-to-peak voltages, and using a cutoff of approximately 2. Our spike sorting software and the authors who created it have used a cutoff around this value (1.8 - 2.5) (Nicholas V. Swindale et al. 2023; Nicholas V. Swindale et al. 2017).\nNote that recent cutting edge electrophysiology papers from the International Brain Laboratory have used a similar cutoff of 2.5 with popular algorithms like Kilosort2 (Inagaki et al. 2022). Superficially, this may appear to be more strict than what I am endorsing. However, note that the equation used by these authors is Equation 1, and with this method, SNR=2.5 is barely distinguishable from noise (Figure 1). Confusingly, about 8 years prior, this group used a SNR cutoff of at least 5 (Guo et al. 2014, fig. S3), with average SNR around 10, which is much more reasonable. These gradual decays in quality over time are an important cautionary tale for understanding the underlying methodology.\n\n\nCode\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport copy\n\ndef get_noise_ptp(noise,samples,repetitions):\n  \n  max_noise = np.zeros(repetitions)\n  min_noise = np.zeros(repetitions)\n  noise_ptp = np.zeros(repetitions)\n  \n  for i in range(0,repetitions):\n    subsamples = np.random.choice(noise_std,samples)\n  \n    max_noise[i] = np.max(noise_std)\n    min_noise[i] = np.min(noise_std)\n    noise_ptp[i] = max_noise[i] - min_noise[i]\n    \n  noise_ptp = np.mean(noise_ptp)\n  max_noise = np.mean(max_noise)\n  min_noise = np.mean(min_noise)\n  \n  return noise_ptp,max_noise,min_noise\n  \n  \n\ntemplate = np.array([-0.1513909 , -0.16631116, -0.17847979, -0.18862691, -0.19872002,\n       -0.20880426, -0.21737931, -0.22361187, -0.22874592, -0.23452372,\n       -0.24082686, -0.24489726, -0.24255492, -0.22836725, -0.19307666,\n       -0.1191242 ,  0.02425   ,  0.28417833,  0.71488001,  1.34970811,\n        2.15717331,  3.00861469,  3.70470693,  4.06647289,  4.02591484,\n        3.64727615,  3.07093063,  2.43142789,  1.8080954 ,  1.2247536 ,\n        0.67450634,  0.14624459, -0.36222091, -0.84091953, -1.2741004 ,\n       -1.6452294 , -1.94012256, -2.14839704, -2.26756383, -2.30440089,\n       -2.27405578, -2.19505695, -2.0840863 , -1.95470787, -1.81895549,\n       -1.68644032, -1.56235016, -1.44811373, -1.3434583 , -1.24678163,\n       -1.15489337, -1.06493637, -0.97600263, -0.88764435, -0.79968051,\n       -0.71323625, -0.62895673, -0.54701365, -0.46780424, -0.39222975,\n       -0.32111773, -0.25396762, -0.19020192, -0.13038235, -0.07453424,\n       -0.02132602,  0.02993237,  0.07660115,  0.11522204,  0.14610511,\n        0.17122906,  0.19176712,  0.20754389])\n\nsnr_values = [2.5, 7.5, 15.0]\nnoise_length = 1000\npad = int((noise_length - len(template)) / 2)\n\nmax_template = np.max(template)\nmin_template = np.min(template)\n\ntemplate_ptp = max_template - min_template\n\n(fig,ax) = plt.subplots(1,len(snr_values))\n\nfor i in range(0,len(snr_values)):\n  \n  snr_value = snr_values[i]\n  padded_template = np.zeros(noise_length)\n\n  noise_std = np.random.normal(loc=0.0,scale=template_ptp / snr_value, size=noise_length)\n\n  noise_ptp,max_noise,min_noise = get_noise_ptp(noise_std,len(template),1000)\n\n  template_over_noise = copy.deepcopy(noise_std)\n  template_over_noise[pad:len(template)+pad] += template\n\n  padded_template[pad:len(template) + pad] += template\n\n  ax[i].plot(template_over_noise,color=\"black\",label=\"_Hidden\",linewidth=1.0)\n  ax[i].plot([0,noise_length],[max_template,max_template],linestyle=\"dashed\",color=\"red\",label=\"_Hidden\")\n  ax[i].plot([0,noise_length],[min_template,min_template],linestyle=\"dashed\",color=\"red\",label=\"Template \\n Envelope\")\n  \n  ax[i].plot([0,noise_length],[max_noise,max_noise],linestyle=\"dashed\",color=\"blue\",label=\"_Hidden\")\n  ax[i].plot([0,noise_length],[min_noise,min_noise],linestyle=\"dashed\",color=\"blue\",label=\"Noise \\n Envelope\")\n  #ax[i].plot(padded_template,color=\"red\",alpha=0.2)\n\n  snr_std = np.around(template_ptp / np.std(noise_std),decimals=1)\n  snr_ptp = np.around(template_ptp / (np.max(noise_std) - np.min(noise_std)),decimals=1)\n\n  ax[i].set_title(f\"SNR_std: {snr_std} \\n SNR_ptp: {snr_ptp}\" )\n  ax[i].set_ylim([-9, 9])\n  ax[i].set_xticks([])\n  ax[i].set_yticks([])\n  ax[i].set_xlabel(\"Time\")\n  \n  if i == 0:\n    ax[i].set_ylabel(\"Voltage\")\n  if i == len(ax) - 1:\n    ax[i].legend()\n\n\n\n\n\nFigure 1: SNR calculation comparisons\n\n\n\n\n\n\n\nThe waveform amplitude is part of the SNR calculation, so it is mostly just a kind of sanity check. Some spike sorting programs report this as the absolute value of the largest peak (positive or negative), while others report it as peak-to-peak voltage, which can be as much as double the size for a bi-phasic waveform. I recommend using a cutoff of 100 uV peak-to-peak, although few single units will have an SNR &gt; 2 with an amplitude smaller than 100uV at physiological noise levels.\n\n\n\nIt is common to report metrics relating to the refractory period. Briefly, neurons are inactivated after firing action potentials for a few milliseconds, so it is reasonably to assume that if a sorting algorithm is detecting more waveforms within this “refractory” window, it is either due to noise or multi-unit contamination.\n\n\nMultiunit is used to refer to signals that appear to be from neural activity, but are not sufficiently well isolated to distinguish from one another\nThis is good in theory, but these metrics can be heavily biased downward as a result of temporal lockout built into sorting algorithms. After most sorting algorithms detect threshold crossings, they generally select the waveform, and then impose some lockout period before they look for more threshold crossings. For this reason, they tend to not even look for spikes during this “lockout period.” So a low ISI violation rate can still occur with low SNR units because of the sorting process itself.\nISI violation is reported in multiple ways. The simplest is to calculate the percentage of total spikes that within 1 refractory period width of one another. These tend to be quite low (1-2%).\nThere are more sophisticated methods that try to estimate proportion of spikes that are contaminated by multiunit spiking. There are lots of assumptions in these (such as uncorrelated units) and a stable mean firing rate, which can make these metrics biased upwards for bursty units like we see in the brainstem. They can be useful however. Often these are reported as between 0-1, roughly corresponding to 0% of spiking is contaminated and 100% contaminated.\n\n\n\nAnalysis of neural data usually requires the unit to be present throughout the course of the entire experiment; otherwise changes in activity may be falsely attributed to changes in behavior over that time. There can be abrupt changes in if a unit is present or not (for instance, bumping the experimental rig), but low SNR units could also come and go as they sink above and below the threshold for detection. Good manual sorting should exclude this second time of unit. Similarly, electrode drift may cause the shape of the neuronal waveform to change over time, and the sorting algorithm may falsely assign part of the activity to one unit, and part to another. Again, manual sorting should be able to catch these errors if the unit is sufficiently high SNR.\nA presence ratio is usually the quantity calculated for this purpose, and 0.95 is a reasonable threshold.\n\n\n\nPre-specify some metrics for spike sorting that will serve as a threshold for including neurons in your analysis. However, most neurons that you call single units after manual curation should meet these thresholds anyway. A reasonable criteria matrix is as follows:\n\nRecommended Quality Metrics\n\n\nSNR (peak-to-peak signal / peak-to-peak noise) &gt; 2\n\n\nAmplitude (peak-to-peak) &gt; 100 uV\n\n\nISI violation &lt; 1%\n\n\nMUA contamination &lt; 0.5\n\n\nPresence ratio &gt; 0.95"
  },
  {
    "objectID": "spikesorter_tutorial.html#sorting",
    "href": "spikesorter_tutorial.html#sorting",
    "title": "Spike Sorting Tutorial",
    "section": "Sorting",
    "text": "Sorting\n\nPreparing and Loading Data\nRun script to convert voltage data into hdf5 file format.\nCopy appropriate electrode.cfg file into folder with voltage.\nLoad HDF5 file into SpikeSorter using sampling rate of 30000 and voltage/bit of 0.195uV\n\n\nPre-processing\nSubtract mean voltage from all channels\nFilter with cutoff of 0.5 Khz high pass\nMask noisy channels\n\n\nEvent Detection\nEvent detection and channel masking\n\n\nClustering\nAutosort\nGuided Merge Split\nView, Clean and Split Clusters\n\n\n\n\n\n\nTip\n\n\n\nConsider Splitting Cluster If …\n\n\n\n\n\nCompare cluster pairs\n\n\n\n\n\n\nTip\n\n\n\nConsider Merging Clusters If …\n\nAsymmetric cross correlation at short time intervals, particularly if second unit has smaller peak-to-peak voltage\nSimilar units where merged ACF preserves refractory period\nSimilar units where the second appears as the first disappears\nBoth units have similar short term firing patterns, based on ACF\nBoth units have similar long-term firing patterns, based on PCs vs experiment time"
  },
  {
    "objectID": "spikesorter_tutorial.html#quality-metrics-revisited",
    "href": "spikesorter_tutorial.html#quality-metrics-revisited",
    "title": "Spike Sorting Tutorial",
    "section": "Quality Metrics Revisited",
    "text": "Quality Metrics Revisited\na"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "docs",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "denoising.html",
    "href": "denoising.html",
    "title": "De-noising for Electrophysiology",
    "section": "",
    "text": "How signal is generated\nHow signal is quantified\npeak-to-peak voltage for extracellular recordings\n\n\n\nHow noise is generated\nHow noise is quantified\nRMS noise vs peak-to-peak noise\nNoise is additive so what\n\n\n\nCommon Mode Rejection Ratio (CMRR)"
  },
  {
    "objectID": "lab_meeting.html",
    "href": "lab_meeting.html",
    "title": "Lab Meeting Checklist",
    "section": "",
    "text": "Histology\nPlace colored labels\n\n\nPlots\nUse Superplots to represent differences in variability across animals / days"
  },
  {
    "objectID": "denoising.html#background",
    "href": "denoising.html#background",
    "title": "De-noising for Electrophysiology",
    "section": "",
    "text": "How signal is generated\nHow signal is quantified\npeak-to-peak voltage for extracellular recordings\n\n\n\nHow noise is generated\nHow noise is quantified\nRMS noise vs peak-to-peak noise\nNoise is additive so what\n\n\n\nCommon Mode Rejection Ratio (CMRR)"
  },
  {
    "objectID": "denoising.html#power",
    "href": "denoising.html#power",
    "title": "De-noising for Electrophysiology",
    "section": "Power",
    "text": "Power\nSwitch mode power supplies are extremely noisy - best to use linear bench power supplies when possible"
  },
  {
    "objectID": "denoising.html#grounding-and-isolation",
    "href": "denoising.html#grounding-and-isolation",
    "title": "De-noising for Electrophysiology",
    "section": "Grounding and Isolation",
    "text": "Grounding and Isolation\n\nFaraday Cage\nOnly works if noise sources are outside the faraday cage. Section 5.1\n\n\nEnsure components are actually connected\nAluminum oxide coating is not conductive and will need to be removed if you expect components to connect together. Particularly troublesome components:\nFor large components: use sand paper to remove paint layer\nFor small components: soak in bleach for several hours\n\nCommon Components With Aluminum Oxide\n\n\n\n\n\n\nComponent\nBest removal\n\n\n\n\nBlack Thorlabs parts\nBleach\n\n\nAluminum breadboard\nSandpaper around specific holes where you wish to connect grounding wire\n\n\nElectronics Rack\nSandpaper around holes, and connect together with wires.\n\n\n\n\n\nMake sure all cables are plugged in\nA long wire is an antenna.\nParticularly bad are long wires running from the outside to inside to your experiment (Section 5.2).\nUnplugging unused electronic equipment may seem like a good idea, but unplugged power cables will be in the noisiest region (hot side) of the electronic rack, and consequently pick up large amounts of noise Section 5.3\n\n\nComputers"
  },
  {
    "objectID": "denoising.html#testing",
    "href": "denoising.html#testing",
    "title": "De-noising for Electrophysiology",
    "section": "Testing",
    "text": "Testing\nUse high impedance or open circuit electrodes. An electrode with infinite impedance is a perfect antenna"
  },
  {
    "objectID": "denoising.html#case-studies",
    "href": "denoising.html#case-studies",
    "title": "De-noising for Electrophysiology",
    "section": "Case Studies",
    "text": "Case Studies\n\nComponents inside the Cage\nLights\nLasers\nExperimental Control\n\n\nUngrounded Camera and Lighting\n\n\nUnplugged Power Cables\nNoisy ground then radiates into cold side of the rack through ground BNC terminals"
  }
]